
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../03_pdfminer_parser_engine_/">
      
      
        <link rel="next" href="../05_layout_analyzer_/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.12">
    
    
      
        <title>Chapter 4: OCR Parser Engine - Backend-mod-api-php</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.2afb09e1.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="https://unpkg.com/mermaid@10.9.1/dist/mermaid.min.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#chapter-4-ocr-parser-engine" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Backend-mod-api-php" class="md-header__button md-logo" aria-label="Backend-mod-api-php" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Backend-mod-api-php
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Chapter 4: OCR Parser Engine
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Backend-mod-api-php" class="md-nav__button md-logo" aria-label="Backend-mod-api-php" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Backend-mod-api-php
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Tutorial: Backend-mod-api-php
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../01_pdf_type_detector_/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter 1: PDF Type Detector
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../02_state_format_specific_parser_/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter 2: State/Format Specific Parser
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../03_pdfminer_parser_engine_/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter 3: PDFMiner Parser Engine
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Chapter 4: OCR Parser Engine
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Chapter 4: OCR Parser Engine
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#the-problem-my-pdf-is-just-a-picture" class="md-nav__link">
    <span class="md-ellipsis">
      The Problem: My PDF is Just a Picture!
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-solution-the-ocr-parser-engine-our-image-reader" class="md-nav__link">
    <span class="md-ellipsis">
      The Solution: The OCR Parser Engine - Our Image Reader
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-does-it-work-the-steps" class="md-nav__link">
    <span class="md-ellipsis">
      How Does It Work? The Steps
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-its-used-in-the-project" class="md-nav__link">
    <span class="md-ellipsis">
      How It's Used in the Project
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#inside-the-engine-a-peek-under-the-hood" class="md-nav__link">
    <span class="md-ellipsis">
      Inside the Engine: A Peek Under the Hood
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusion
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../05_layout_analyzer_/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter 5: Layout Analyzer
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../06_data_extraction___transformation_/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter 6: Data Extraction &amp; Transformation
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../07_json_output_formatter_/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter 7: JSON Output Formatter
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#the-problem-my-pdf-is-just-a-picture" class="md-nav__link">
    <span class="md-ellipsis">
      The Problem: My PDF is Just a Picture!
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-solution-the-ocr-parser-engine-our-image-reader" class="md-nav__link">
    <span class="md-ellipsis">
      The Solution: The OCR Parser Engine - Our Image Reader
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-does-it-work-the-steps" class="md-nav__link">
    <span class="md-ellipsis">
      How Does It Work? The Steps
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-its-used-in-the-project" class="md-nav__link">
    <span class="md-ellipsis">
      How It's Used in the Project
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#inside-the-engine-a-peek-under-the-hood" class="md-nav__link">
    <span class="md-ellipsis">
      Inside the Engine: A Peek Under the Hood
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusion
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="chapter-4-ocr-parser-engine">Chapter 4: OCR Parser Engine</h1>
<p>In the <a href="../03_pdfminer_parser_engine_/">previous chapter</a>, we learned about the <a href="../03_pdfminer_parser_engine_/">PDFMiner Parser Engine</a>, our tool for reading PDFs where the text is already stored like in a normal document. It's great when we can just select and copy the text directly from the PDF.</p>
<p>But what happens when the PDF isn't like that?</p>
<h2 id="the-problem-my-pdf-is-just-a-picture">The Problem: My PDF is Just a Picture!</h2>
<p>Imagine someone scans a paper mod worksheet or takes a photo of it and saves it as a PDF. When you open this PDF, you can't select the text. It's basically just an image wrapped inside a PDF file.</p>
<p>Our <a href="../03_pdfminer_parser_engine_/">PDFMiner Parser Engine</a> can't read text from an image. It's like asking it to read a book where all the pages are photographs â€“ it only understands actual typed characters, not pictures of characters.</p>
<p>How can our system read the "Risk ID" or "Effective Date" from these scanned or image-based PDFs?</p>
<h2 id="the-solution-the-ocr-parser-engine-our-image-reader">The Solution: The OCR Parser Engine - Our Image Reader</h2>
<p>This is where the <strong>OCR Parser Engine</strong> steps in! OCR stands for <strong>Optical Character Recognition</strong>.</p>
<p>Think of this engine like a super-smart app on your phone. You take a picture of a page from a book or a sign, and the app magically recognizes the text in the picture, allowing you to copy or search it.</p>
<p>The OCR Parser Engine does something very similar for our PDF documents:</p>
<ol>
<li><strong>Sees the Image:</strong> It takes the PDF page, which is essentially an image.</li>
<li><strong>Recognizes Characters:</strong> It analyzes the image to identify shapes that look like letters and numbers.</li>
<li><strong>Reads the Text:</strong> It converts those recognized shapes back into actual text characters that the computer can understand.</li>
<li><strong>Notes the Location:</strong> Just like PDFMiner, it also figures out <em>where</em> on the page each piece of recognized text is located (its bounding box or coordinates).</li>
</ol>
<p>This engine is specifically designed to handle PDFs that the <a href="../01_pdf_type_detector_/">PDF Type Detector</a> identified as needing OCR (often flagged with a code like '1' or '2').</p>
<h2 id="how-does-it-work-the-steps">How Does It Work? The Steps</h2>
<p>The OCR Parser Engine uses a combination of tools to achieve this "image reading":</p>
<ol>
<li><strong>PDF to Image:</strong> First, it needs to get the actual image out of the PDF page. It uses a tool called <code>pdf2image</code> to convert each page of the PDF into an image file (like a TIFF or PNG).</li>
<li><strong>Image Cleanup (Optional):</strong> Sometimes, scanned images are messy (skewed, dark, noisy). The engine <em>might</em> use image processing libraries like OpenCV (<code>cv2</code>), NumPy (<code>numpy</code>), or Pillow (<code>PIL</code>) to clean up the image or isolate specific parts before trying to read it. This helps improve the accuracy of the text recognition. (This cleanup is often done within the specific OCR parser scripts like <code>ocrCA.py</code>).</li>
<li><strong>Send to the Expert (Google Cloud Vision):</strong> The core of the OCR process happens here. The engine takes the prepared image and sends it to a powerful cloud service from Google called <strong>Google Cloud Vision API</strong> (<code>vision_v1</code>). This service is highly specialized in analyzing images, including reading text.</li>
<li><strong>Get the Results:</strong> Google Cloud Vision analyzes the image and sends back the text it found, along with the coordinates (bounding boxes) for each word or character.</li>
</ol>
<h2 id="how-its-used-in-the-project">How It's Used in the Project</h2>
<p>Let's follow the journey of a scanned PDF:</p>
<ol>
<li><strong>Detection:</strong> The <a href="../01_pdf_type_detector_/">PDF Type Detector</a> looks at <code>scanned_form.pdf</code> and realizes it can't read the text directly. It tells the system, "This needs OCR (Type '1')".</li>
<li><strong>Routing:</strong> The system sends the PDF to the appropriate <a href="../02_state_format_specific_parser_/">State/Format Specific Parser</a> that handles OCR for that type (e.g., <code>ocrCA.py</code> if it might be a scanned California form).</li>
<li><strong>Request:</strong> The <code>ocrCA.py</code> parser knows it needs OCR. It asks the <strong>OCR Parser Engine</strong>: "Please read the text from this scanned PDF page."</li>
<li><strong>Processing (OCR Engine):</strong><ul>
<li>Converts the PDF page to an image using <code>pdf2image</code>.</li>
<li>(Optionally cleans the image using <code>cv2</code>/<code>PIL</code>).</li>
<li>Sends the image to Google Cloud Vision API.</li>
<li>Receives the detected text and coordinates.</li>
</ul>
</li>
<li>
<p><strong>Response:</strong> The OCR Engine returns a list of detected words and their locations to the <code>ocrCA.py</code> parser. This list might look something like this (simplified):</p>
<p><div class="highlight"><pre><span></span><code>[
  # [ [[X1,Y1],[X2,Y2],[X3,Y3],[X4,Y4]], &#39;DetectedWord&#39; ],
  [ [[50, 700], [150, 700], [150, 715], [50, 715]], &#39;Bureau&#39; ],
  [ [[160, 700], [190, 700], [190, 715], [160, 715]], &#39;No.&#39; ],
  [ [[200, 700], [260, 700], [260, 715], [200, 715]], &#39;123456&#39; ],
  # ... and many more words
]
</code></pre></div>
<em>(Each word has 4 corner points defining its bounding box.)</em>
6.  <strong>Usage:</strong> The <code>ocrCA.py</code> parser then uses this list and its specific layout rules (like finding text <em>near</em> the word "Bureau") to extract the required data fields, just like we saw in <a href="../02_state_format_specific_parser_/">Chapter 2</a>.</p>
</li>
</ol>
<h2 id="inside-the-engine-a-peek-under-the-hood">Inside the Engine: A Peek Under the Hood</h2>
<p>Let's visualize the process when a specific OCR parser script (like <code>ocrCA.py</code>) uses the OCR Engine:</p>
<pre class="mermaid"><code>sequenceDiagram
    participant Parser as OCR Specific Parser (e.g., ocrCA.py)
    participant Engine as OCR Parser Engine
    participant PDF2Image as pdf2image Tool
    participant GCV as Google Cloud Vision API

    Parser-&gt;&gt;Engine: Process this scanned PDF page: 'scan_page.pdf'
    Engine-&gt;&gt;PDF2Image: Convert PDF page to Image
    PDF2Image--&gt;&gt;Engine: Return Image data
    Engine-&gt;&gt;GCV: Please OCR this Image data
    GCV--&gt;&gt;Engine: Here's the text found and its bounding boxes
    Engine--&gt;&gt;Parser: Return list of [ [Coords], 'Word' ]</code></pre>
<p>Now, let's look at <em>simplified</em> code concepts inspired by the OCR scripts (<code>ocrCA.py</code>, <code>ocrNC.py</code>, etc.).</p>
<p><strong>Step 1: Converting PDF Page to Image (using <code>pdf2image</code>)</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># Simplified concept using pdf2image</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pdf2image</span><span class="w"> </span><span class="kn">import</span> <span class="n">convert_from_path</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Get the path to the PDF</span>
<span class="n">pdf_path</span> <span class="o">=</span> <span class="s1">&#39;scanned_form.pdf&#39;</span>
<span class="n">page_number_to_convert</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># Example: process the first page</span>

<span class="c1"># Convert the specific page to an image object (using Pillow - PIL)</span>
<span class="n">images</span> <span class="o">=</span> <span class="n">convert_from_path</span><span class="p">(</span><span class="n">pdf_path</span><span class="p">,</span> <span class="n">first_page</span><span class="o">=</span><span class="n">page_number_to_convert</span><span class="p">,</span> <span class="n">last_page</span><span class="o">=</span><span class="n">page_number_to_convert</span><span class="p">)</span>
<span class="n">image_page_1</span> <span class="o">=</span> <span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># Get the image for the first page</span>

<span class="c1"># Convert the image to a format OpenCV (cv2) or Google Vision can use</span>
<span class="n">image_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">image_page_1</span><span class="p">)</span>

<span class="c1"># &#39;image_np&#39; now holds the pixel data for the page image</span>
</code></pre></div>
<ul>
<li><strong>Explanation:</strong> This code uses the <code>convert_from_path</code> function from the <code>pdf2image</code> library to turn page 1 of our PDF into an image. We then convert it into a format (<code>numpy</code> array) that other image tools can work with.</li>
</ul>
<p><strong>Step 2: Detecting Text with Google Cloud Vision (Simplified <code>detect</code> function)</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># Simplified concept using google.cloud.vision_v1</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">google.cloud</span><span class="w"> </span><span class="kn">import</span> <span class="n">vision_v1</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">io</span>

<span class="c1"># Assume &#39;image_np&#39; contains the image data from the previous step</span>
<span class="c1"># Need to encode the image (e.g., as TIFF or PNG)</span>
<span class="c1"># (Code to encode &#39;image_np&#39; into &#39;image_content&#39; bytes goes here)</span>
<span class="c1"># For example, using OpenCV:</span>
<span class="c1"># _, encoded_image = cv2.imencode(&#39;.tiff&#39;, image_np)</span>
<span class="c1"># image_content = encoded_image.tobytes()</span>

<span class="c1"># --- Pretend we have &#39;image_content&#39; ---</span>
<span class="n">image_content</span> <span class="o">=</span> <span class="sa">b</span><span class="s1">&#39;...&#39;</span> <span class="c1"># Placeholder for actual image bytes</span>

<span class="c1"># Prepare the request for Google Cloud Vision</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">vision_v1</span><span class="o">.</span><span class="n">ImageAnnotatorClient</span><span class="p">()</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">vision_v1</span><span class="o">.</span><span class="n">Image</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">image_content</span><span class="p">)</span>
<span class="n">feature</span> <span class="o">=</span> <span class="n">vision_v1</span><span class="o">.</span><span class="n">Feature</span><span class="p">(</span><span class="n">type_</span><span class="o">=</span><span class="n">vision_v1</span><span class="o">.</span><span class="n">Feature</span><span class="o">.</span><span class="n">Type</span><span class="o">.</span><span class="n">DOCUMENT_TEXT_DETECTION</span><span class="p">)</span>
<span class="n">request</span> <span class="o">=</span> <span class="n">vision_v1</span><span class="o">.</span><span class="n">AnnotateImageRequest</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">features</span><span class="o">=</span><span class="p">[</span><span class="n">feature</span><span class="p">])</span>

<span class="c1"># Send the request and get the response</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">annotate_image</span><span class="p">(</span><span class="n">request</span><span class="o">=</span><span class="n">request</span><span class="p">)</span>

<span class="c1"># Process the response (Simplified)</span>
<span class="n">detected_words</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">word_coordinates</span> <span class="o">=</span> <span class="p">[]</span>
<span class="c1"># (Loop through response.full_text_annotation.pages...blocks...paragraphs...words)</span>
<span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">full_text_annotation</span><span class="o">.</span><span class="n">pages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">blocks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">paragraphs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">words</span><span class="p">:</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">symbol</span><span class="o">.</span><span class="n">text</span> <span class="k">for</span> <span class="n">symbol</span> <span class="ow">in</span> <span class="n">word</span><span class="o">.</span><span class="n">symbols</span><span class="p">])</span>
    <span class="n">coords</span> <span class="o">=</span> <span class="p">[[</span><span class="n">v</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">y</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">word</span><span class="o">.</span><span class="n">bounding_box</span><span class="o">.</span><span class="n">vertices</span><span class="p">]</span>
    <span class="n">detected_words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">word_coordinates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">coords</span><span class="p">)</span>

<span class="c1"># Now &#39;detected_words&#39; and &#39;word_coordinates&#39; hold the OCR results</span>
<span class="c1"># print(list(zip(word_coordinates, detected_words)))</span>
<span class="c1"># Output might look like:</span>
<span class="c1"># [ ([ [50,700], ... ], &#39;Bureau&#39;), ([ [160,700], ... ], &#39;No.&#39;), ... ]</span>
</code></pre></div>
<ul>
<li><strong>Explanation:</strong> This simplified code first gets the image data into the right format (<code>image_content</code>). It then creates a request telling Google Cloud Vision we want to perform <code>DOCUMENT_TEXT_DETECTION</code>. It sends the image using the <code>client.annotate_image</code> function. Finally, it loops through the <code>response</code> (which has a complex structure) to pull out each detected <code>word</code>, its <code>text</code>, and its boundary <code>coords</code>.</li>
</ul>
<p>These extracted words and coordinates are exactly what the specific OCR parsers (like <code>ocrCA.py</code> or <code>ocrNC.py</code>) need to start finding the data based on keywords and relative positions.</p>
<h2 id="conclusion">Conclusion</h2>
<p>The OCR Parser Engine is our essential tool for reading PDFs that are just images or scans. It acts like a smart scanner app, using <code>pdf2image</code> to get the image and then leveraging the power of Google Cloud Vision API to recognize the text and its location on the page. This allows the <a href="../02_state_format_specific_parser_/">State/Format Specific Parser</a> to process even scanned documents.</p>
<p>Now we've seen how the system gets text data from <em>both</em> text-based PDFs (<a href="../03_pdfminer_parser_engine_/">PDFMiner Parser Engine</a>) and image-based PDFs (OCR Parser Engine). But just having the text and its location isn't enough. How does the system actually <em>understand</em> the layout and find specific fields like "Risk ID"? That's the job of the next component.</p>
<p><strong>Next:</strong> <a href="../05_layout_analyzer_/">Chapter 5: Layout Analyzer</a></p>
<hr />












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.c8b220af.min.js"></script>
      
        <script src="https://unpkg.com/mermaid@10.9.1/dist/mermaid.min.js"></script>
      
    
  </body>
</html>